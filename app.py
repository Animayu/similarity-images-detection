import streamlit as st
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from PIL import Image
from imagededup.methods import CNN, PHash
from imagededup.utils import plot_duplicates
import pickle
from datetime import datetime
import io
import base64
from sklearn.metrics.pairwise import cosine_similarity

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å›¾ç‰‡ç›¸ä¼¼åº¦æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ‡é¢˜å’Œä»‹ç»
st.title("å›¾ç‰‡ç›¸ä¼¼åº¦æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ")
st.markdown("""
æœ¬ç³»ç»Ÿç”¨äºæ£€æµ‹ä¸è¾“å…¥å›¾åƒç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼çš„å›¾åƒï¼Œè¾…åŠ©é˜²æ¬ºè¯ˆæ£€æµ‹ã€‚æ”¯æŒCNNå’ŒpHashä¸¤ç§ç®—æ³•ã€‚
- **CNN**ï¼šåŸºäºæ·±åº¦å­¦ä¹ ç‰¹å¾ï¼Œé€‚åˆè¯­ä¹‰çº§ç›¸ä¼¼æ€§æ£€æµ‹
- **pHash**ï¼šåŸºäºæ„ŸçŸ¥å“ˆå¸Œï¼Œé€‚åˆè½»å¾®å˜åŒ–å›¾ç‰‡çš„å¿«é€Ÿæ£€æµ‹
""")

# ä¾§è¾¹æ  - å‚æ•°è®¾ç½®
st.sidebar.header("å‚æ•°è®¾ç½®")

# é€‰æ‹©ç®—æ³•
algorithm = st.sidebar.selectbox(
    "é€‰æ‹©ç®—æ³•",
    ["CNN", "pHash", "ä¸¤ç§æ–¹æ³•éƒ½ä½¿ç”¨"]
)

# è®¾ç½®é˜ˆå€¼
if algorithm == "CNN" or algorithm == "ä¸¤ç§æ–¹æ³•éƒ½ä½¿ç”¨":
    cnn_threshold = st.sidebar.slider(
        "CNNç›¸ä¼¼åº¦é˜ˆå€¼ (è¶Šé«˜è¦æ±‚è¶Šç›¸ä¼¼)", 
        min_value=0.5, 
        max_value=1.0, 
        value=0.85,
        step=0.01
    )

if algorithm == "pHash" or algorithm == "ä¸¤ç§æ–¹æ³•éƒ½ä½¿ç”¨":
    phash_threshold = st.sidebar.slider(
        "pHashè·ç¦»é˜ˆå€¼ (è¶Šä½è¦æ±‚è¶Šç›¸ä¼¼)", 
        min_value=0, 
        max_value=20, 
        value=8,
        step=1
    )

# è®¾ç½®æ˜¾ç¤ºçš„æœ€ç›¸ä¼¼å›¾ç‰‡æ•°é‡
top_n = st.sidebar.slider(
    "æ˜¾ç¤ºæœ€ç›¸ä¼¼çš„å›¾ç‰‡æ•°é‡", 
    min_value=1, 
    max_value=10, 
    value=5
)

# è®¾ç½®å›¾ç‰‡åº“è·¯å¾„
image_library_path = st.sidebar.text_input(
    "å›¾ç‰‡åº“è·¯å¾„",
    value="./input/test_images/"
)

# ç»“æœå¯¼å‡ºè®¾ç½®
export_results = st.sidebar.checkbox("å¯¼å‡ºç»“æœ", value=True)

# æ•°æ®åŠ è½½å’Œå¤„ç†å‡½æ•°
@st.cache_data
def load_image_files(image_dir):
    """åŠ è½½å›¾ç‰‡åº“ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶è·¯å¾„"""
    if not os.path.exists(image_dir):
        return []
    
    image_files = [f for f in os.listdir(image_dir) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    return image_files

# æ£€æŸ¥å¹¶åˆ›å»ºç‰¹å¾ç¼“å­˜ç›®å½•
cache_dir = "./cache"
if not os.path.exists(cache_dir):
    os.makedirs(cache_dir)

# ç‰¹å¾ç¼–ç å’Œç¼“å­˜å‡½æ•°
@st.cache_data
def get_cnn_encodings(image_dir):
    """è·å–æ‰€æœ‰å›¾ç‰‡çš„CNNç¼–ç ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    cache_file = os.path.join(cache_dir, "cnn_encodings.pkl")
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            encodings = pickle.load(f)
        st.sidebar.success(f"å·²åŠ è½½CNNç¼–ç ç¼“å­˜ï¼ŒåŒ…å«{len(encodings)}å¼ å›¾ç‰‡")
        return encodings
    
    # æ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡Œç¼–ç 
    with st.spinner("æ­£åœ¨è¿›è¡ŒCNNç¼–ç ï¼Œé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
        cnn = CNN()
        encodings = cnn.encode_images(image_dir=image_dir)
        
        # ä¿å­˜ç¼“å­˜
        with open(cache_file, 'wb') as f:
            pickle.dump(encodings, f)
        
        st.sidebar.success(f"CNNç¼–ç å®Œæˆï¼Œå·²ç¼“å­˜{len(encodings)}å¼ å›¾ç‰‡çš„ç‰¹å¾")
        return encodings

@st.cache_data
def get_phash_encodings(image_dir):
    """è·å–æ‰€æœ‰å›¾ç‰‡çš„pHashç¼–ç ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    cache_file = os.path.join(cache_dir, "phash_encodings.pkl")
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            encodings = pickle.load(f)
        st.sidebar.success(f"å·²åŠ è½½pHashç¼–ç ç¼“å­˜ï¼ŒåŒ…å«{len(encodings)}å¼ å›¾ç‰‡")
        return encodings
    
    # æ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡Œç¼–ç 
    with st.spinner("æ­£åœ¨è¿›è¡ŒpHashç¼–ç ï¼Œé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
        phasher = PHash()
        encodings = phasher.encode_images(image_dir=image_dir)
        
        # ä¿å­˜ç¼“å­˜
        with open(cache_file, 'wb') as f:
            pickle.dump(encodings, f)
        
        st.sidebar.success(f"pHashç¼–ç å®Œæˆï¼Œå·²ç¼“å­˜{len(encodings)}å¼ å›¾ç‰‡çš„ç‰¹å¾")
        return encodings

# å›¾ç‰‡ç¼–ç å‡½æ•°
def encode_uploaded_image(img, method="cnn"):
    """å¯¹ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œç¼–ç """
    if method == "cnn":
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_img_path = os.path.join(cache_dir, "temp_upload.jpg")
        img.save(temp_img_path)
        
        cnn = CNN()
        # ç¼–ç å•ä¸ªå›¾ç‰‡
        encoding = cnn.encode_image(image_file=temp_img_path)
        return encoding
    
    elif method == "phash":
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_img_path = os.path.join(cache_dir, "temp_upload.jpg")
        img.save(temp_img_path)
        
        phasher = PHash()
        # ç¼–ç å•ä¸ªå›¾ç‰‡
        encoding = phasher.encode_image(image_file=temp_img_path)
        return encoding
    
    return None

# ç»“æœå¯è§†åŒ–å‡½æ•°
def visualize_results(uploaded_img, similar_images, scores, image_dir, method_name):
    """å¯è§†åŒ–ç›¸ä¼¼å›¾ç‰‡ç»“æœ"""
    # æ˜¾ç¤ºåŸå§‹ä¸Šä¼ å›¾ç‰‡
    st.subheader(f"{method_name}æ–¹æ³•æ£€æµ‹ç»“æœ")
    
    # å¦‚æœæ²¡æœ‰ç›¸ä¼¼å›¾ç‰‡
    if not similar_images:
        st.warning(f"æœªå‘ç°ç›¸ä¼¼å›¾ç‰‡ (ä½¿ç”¨{method_name}æ–¹æ³•)")
        return
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    results_data = []
    
    # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºå›¾ç‰‡
    cols = st.columns(len(similar_images) + 1)
    
    # ç¬¬ä¸€åˆ—æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡
    with cols[0]:
        st.image(uploaded_img, caption="ä¸Šä¼ å›¾ç‰‡", use_column_width=True)
    
    # å…¶ä½™åˆ—æ˜¾ç¤ºç›¸ä¼¼å›¾ç‰‡
    for i, (img_name, score) in enumerate(zip(similar_images, scores)):
        img_path = os.path.join(image_dir, img_name)
        if os.path.exists(img_path):
            with cols[i+1]:
                img = Image.open(img_path)
                st.image(img, caption=f"ç›¸ä¼¼åº¦: {score:.3f}", use_column_width=True)
                st.markdown(f"**æ–‡ä»¶å**: {img_name}")
                
                # æ”¶é›†ç»“æœæ•°æ®
                results_data.append({
                    "æ£€æµ‹æ–¹æ³•": method_name,
                    "ç›¸ä¼¼å›¾ç‰‡": img_name,
                    "ç›¸ä¼¼åº¦åˆ†æ•°": score
                })
    
    return pd.DataFrame(results_data)

# å¯¼å‡ºç»“æœå‡½æ•°
def get_download_link(df, filename="results.csv"):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">ä¸‹è½½ {filename}</a>'
    return href

def compute_cosine_similarity(vec1, vec2):
    """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    vec1_reshaped = np.array(vec1).reshape(1, -1)
    vec2_reshaped = np.array(vec2).reshape(1, -1)
    return cosine_similarity(vec1_reshaped, vec2_reshaped)[0][0]

# ä¸»è¦åº”ç”¨é€»è¾‘
def main():
    # æ£€æŸ¥å›¾ç‰‡åº“è·¯å¾„
    if not os.path.exists(image_library_path):
        st.error(f"å›¾ç‰‡åº“è·¯å¾„ {image_library_path} ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„è®¾ç½®ã€‚")
        return
    
    # åŠ è½½å›¾ç‰‡æ–‡ä»¶
    image_files = load_image_files(image_library_path)
    if not image_files:
        st.warning(f"å›¾ç‰‡åº“ {image_library_path} ä¸­æ²¡æœ‰å‘ç°å›¾ç‰‡æ–‡ä»¶ã€‚")
        return
    
    st.info(f"å·²åŠ è½½å›¾ç‰‡åº“ï¼ŒåŒ…å« {len(image_files)} å¼ å›¾ç‰‡ã€‚")
    
    # æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
    st.header("ä¸Šä¼ å›¾ç‰‡è¿›è¡Œç›¸ä¼¼æ€§æ£€æµ‹")
    
    uploaded_file = st.file_uploader("é€‰æ‹©å›¾ç‰‡ä¸Šä¼ ", type=["jpg", "jpeg", "png"])
    
    results_dfs = []  # å­˜å‚¨å„æ–¹æ³•çš„ç»“æœ
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºè¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡
        img = Image.open(uploaded_file)
        st.image(img, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=400)
        
        # æ ¹æ®é€‰æ‹©çš„ç®—æ³•æ‰§è¡Œç›¸ä¼¼æ€§æ£€æµ‹
        if algorithm in ["CNN", "ä¸¤ç§æ–¹æ³•éƒ½ä½¿ç”¨"]:
            # æ›´æ–°è¿›åº¦
            status_text.text("å‡†å¤‡CNNç¼–ç ...")
            progress_bar.progress(10)
            
            # è·å–åº“ä¸­æ‰€æœ‰å›¾ç‰‡çš„CNNç¼–ç 
            cnn_encodings = get_cnn_encodings(image_library_path)
            
            # æ›´æ–°è¿›åº¦
            status_text.text("å¯¹ä¸Šä¼ å›¾ç‰‡è¿›è¡ŒCNNç¼–ç ...")
            progress_bar.progress(30)
            
            # ç¼–ç ä¸Šä¼ çš„å›¾ç‰‡
            uploaded_encoding = encode_uploaded_image(img, method="cnn")
            
            # æ›´æ–°è¿›åº¦
            status_text.text("è®¡ç®—CNNç›¸ä¼¼åº¦...")
            progress_bar.progress(50)
            
            # è®¡ç®—ä¸æ‰€æœ‰å›¾ç‰‡çš„ç›¸ä¼¼åº¦
            cnn_scores = {}
            for img_name, encoding in cnn_encodings.items():
                if encoding is not None and uploaded_encoding is not None:
                    similarity = compute_cosine_similarity(uploaded_encoding, encoding)
                    cnn_scores[img_name] = similarity
            
            # æ ¹æ®ç›¸ä¼¼åº¦æ’åº
            sorted_cnn = sorted(cnn_scores.items(), key=lambda x: x[1], reverse=True)
            
            # ç­›é€‰é«˜äºé˜ˆå€¼çš„ç»“æœ
            filtered_cnn = [item for item in sorted_cnn if item[1] >= cnn_threshold]
            
            # å–å‰Nä¸ªç»“æœ
            top_cnn = filtered_cnn[:top_n]
            
            # æ›´æ–°è¿›åº¦
            status_text.text("CNNåˆ†æå®Œæˆ")
            progress_bar.progress(70)
            
            # å¯è§†åŒ–ç»“æœ
            if top_cnn:
                similar_images = [item[0] for item in top_cnn]
                scores = [item[1] for item in top_cnn]
                cnn_df = visualize_results(img, similar_images, scores, image_library_path, "CNN")
                if cnn_df is not None:
                    results_dfs.append(cnn_df)
            else:
                st.warning("æœªå‘ç°ç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼çš„å›¾ç‰‡ (CNNæ–¹æ³•)")
        
        if algorithm in ["pHash", "ä¸¤ç§æ–¹æ³•éƒ½ä½¿ç”¨"]:
            # æ›´æ–°è¿›åº¦
            status_text.text("å‡†å¤‡pHashç¼–ç ...")
            progress_bar.progress(75)
            
            # è·å–åº“ä¸­æ‰€æœ‰å›¾ç‰‡çš„pHashç¼–ç 
            phash_encodings = get_phash_encodings(image_library_path)
            
            # æ›´æ–°è¿›åº¦
            status_text.text("å¯¹ä¸Šä¼ å›¾ç‰‡è¿›è¡ŒpHashç¼–ç ...")
            progress_bar.progress(85)
            
            # ç¼–ç ä¸Šä¼ çš„å›¾ç‰‡
            uploaded_phash = encode_uploaded_image(img, method="phash")
            
            # æ›´æ–°è¿›åº¦
            status_text.text("è®¡ç®—pHashè·ç¦»...")
            progress_bar.progress(90)
            
            # åˆå§‹åŒ–PHashå¯¹è±¡ç”¨äºè®¡ç®—è·ç¦»
            phasher = PHash()
            
            # è®¡ç®—ä¸æ‰€æœ‰å›¾ç‰‡çš„æ±‰æ˜è·ç¦»
            phash_distances = {}
            for img_name, encoding in phash_encodings.items():
                if encoding is not None and uploaded_phash is not None:
                    distance = phasher._hamming_distance(uploaded_phash, encoding)
                    phash_distances[img_name] = distance
            
            # æ ¹æ®è·ç¦»æ’åºï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
            sorted_phash = sorted(phash_distances.items(), key=lambda x: x[1])
            
            # ç­›é€‰ä½äºé˜ˆå€¼çš„ç»“æœ
            filtered_phash = [item for item in sorted_phash if item[1] <= phash_threshold]
            
            # å–å‰Nä¸ªç»“æœ
            top_phash = filtered_phash[:top_n]
            
            # æ›´æ–°è¿›åº¦
            status_text.text("pHashåˆ†æå®Œæˆ")
            progress_bar.progress(100)
            
            # å¯è§†åŒ–ç»“æœ
            if top_phash:
                similar_images = [item[0] for item in top_phash]
                # å¯¹äºpHashï¼Œæˆ‘ä»¬ç”¨1.0å‡å»å½’ä¸€åŒ–çš„è·ç¦»ä½œä¸º"ç›¸ä¼¼åº¦åˆ†æ•°"
                # æ±‰æ˜è·ç¦»èŒƒå›´æ˜¯[0, 64]ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨(64-distance)/64ä½œä¸ºç›¸ä¼¼åº¦
                scores = [(64 - item[1]) / 64 for item in top_phash]
                phash_df = visualize_results(img, similar_images, scores, image_library_path, "pHash")
                if phash_df is not None:
                    results_dfs.append(phash_df)
            else:
                st.warning("æœªå‘ç°ç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼çš„å›¾ç‰‡ (pHashæ–¹æ³•)")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœå¹¶å¯¼å‡º
        if results_dfs and export_results:
            all_results = pd.concat(results_dfs)
            st.header("å¯¼å‡ºæ£€æµ‹ç»“æœ")
            
            # ç”Ÿæˆæ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹ç»“æœ_{timestamp}.csv"
            
            st.markdown(get_download_link(all_results, filename=filename), unsafe_allow_html=True)
            
            # æ˜¾ç¤ºç»“æœè¡¨æ ¼
            st.subheader("æ£€æµ‹ç»“æœæ‘˜è¦")
            st.dataframe(all_results)

    # é¡µé¢åº•éƒ¨æ°´å°
    st.markdown(
        """
        <div style='text-align: right; color: #888888; font-size: 12px; margin-top: 40px;'>
            Â© æ•°æ®ä¸­å°éƒ¨ Â· æ•°æ®æŒ–æ˜ç»„
        </div>
        """,
        unsafe_allow_html=True
    )

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    main() 